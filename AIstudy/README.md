# 결정트리
결정 트리(Decision Tree) : 데이터의 특성(feature)에 대한 '스무고개'같은 **if-then 질문(규칙)+**을 반복하여 데이터를 분류하거나 값을 예측하는 지도학습 알고리즘

<원리>  
  1. 현재 데이터(부모 노드)를 균일하도록 쪼갤 수 있는 '특성', '경계값'을 찾는다. (정보이득 or 지니계수 사용)  
  2. 찾은 조건을 기준으로 서브 데이터 세트로 나눈다.  
  3. 위 과정을 반복한다.  
  4. 노드가 순수해지면 정지 or 하이퍼파라미터로 강제정지  

정보이득 : 1 - 엔트로피 지수 (서로 다른값이 섞여있으면 엔트로피 높음, 같은 값이 섞여있으면 엔트로피 낮음)  
지니계수 : 0수렴 -> 평등, 1수렴 -> 불평등

<특징>  
* 장점  
    1. 알고리즘이 쉽고 직관적  
    2. 시각화 표현 가능  
    3. 특별한 경우 제외 스케일링, 정규화 같은 전처리 작업 필요없다.  
* 단점  
    1. 과적합으로 정확도가 떨어짐 (보완: 트리의 크기를 사전에 제한하는 튜닝)

<파라미터>  
  - min_samples_split : 노드를 분할하기 위한 최소한의 샘플 데이터 수 (default = 2)  
  - min_samples_leaf  : 분할 후 왼쪽, 오른쪽 브랜치 노드에서 가져야할 최소한의 샘플 데이터 수

---
# k평균(mean)
K-평균(K-Means) : 데이터를 K개의 그룹으로 나누기 위해, 각 데이터가 가장 가까운 '중심점(평균)'에 속하도록 반복계산하여 군집을 형성하는 비지도 학습 알고리즘

